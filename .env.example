# DegenBrain Subnet 90 - Configuration Template
# Copy this file to .env and update with your values

# ============================================================================
# REQUIRED CONFIGURATION
# ============================================================================
WALLET_NAME=your_wallet_name_here   # Your Bittensor wallet name
API_URL="https://api.subnet90.com"  # DegenBrain API endpoint

MINER_1_HOTKEY=miner_1        # Miner 1 (default: miner_1)
#MINER_2_HOTKEY=miner_2        # Miner 2 (default: miner_2)
#MINER_3_HOTKEY=miner_3        # Miner 3 (default: miner_3)
#VALIDATOR_HOTKEY=validator    # Validator (default: validator)

# ============================================================================
# OPTIONAL OVERRIDES (All have sensible defaults)
# ============================================================================

# Network Configuration
NETWORK=finney                # Bittensor network (default: finney)
SUBNET_UID=90                 # Subnet number (default: 90)

# Miner Configuration
MINER_STRATEGY=ai_reasoning         # Strategy: dummy, ai_reasoning (default: dummy)
MINER_PORT=12701               # Miner port (auto-assigned: 8091, 8092, 8093)

# Validator Configuration  
# VALIDATOR_PORT=9091           # Validator port (default: 9091)

# Performance Configuration
MAX_WORKERS=4                 # Max worker threads (default: 4)
REQUEST_TIMEOUT=30            # Request timeout in seconds (default: 30)

# Logging Configuration
LOG_LEVEL=INFO                # Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
LOG_FORMAT=json               # Log format: json or text (default: json)

# ============================================================================
# AI MODEL CONFIGURATION (Optional - only for AI strategies)
# ============================================================================
LLM_PROVIDER=openrouter       # Provider: openai, anthropic, groq, gemini, openrouter, chutes

# OpenAI Configuration
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=your_openai_model_here        # Model: gpt-4o, gpt-4-turbo, gpt-3.5-turbo

# Anthropic Configuration  
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=your_anthropic_model_here  # Model: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307

# Groq Configuration (LLaMA 3)
# GROQ_API_KEY=your_groq_api_key_here
# GROQ_MODEL=your_groq_model_here           # Model: llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768

# Google Gemini Configuration
# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_MODEL=your_gemini_model_here          # Model: gemini-1.5-pro, gemini-pro

# OpenRouter Configuration (Mistral, etc.)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=your_openrouter_model_here  # Many models available

# Chutes (Bittensor) Configuration - Decentralized LLM inference
# CHUTES_CPK_API_KEY=your_cpk_api_key_here      # CPK API key from chutes register
# CHUTES_SLUG=your-username-model-slug          # Your deployed chute slug (e.g., username-llama-3-2-3b-instruct)
# CHUTES_MODEL=unsloth/Llama-3.2-3B-Instruct   # Model name used in your chute

# ============================================================================
# DATA SOURCE API KEYS (Optional - for real-time data)
# ============================================================================
COINGECKO_API_KEY=your_coingecko_pro_api_key_here


# ============================================================================
# MONITORING (Optional)
# ============================================================================
# WANDB_API_KEY=your_wandb_api_key_here
# WANDB_PROJECT=degenbrain-subnet
# WANDB_ENTITY=your_wandb_entity_here
